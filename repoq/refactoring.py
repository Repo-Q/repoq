"""Refactoring task generation based on PCE (Proof of Correct Execution) algorithm.

This module implements automated refactoring task generation using greedy
k-repair selection based on Î”Q impact estimation.

Algorithm:
    1. Load baseline quality metrics from JSON-LD
    2. Calculate Î”Q for each file (impact of fixing issues)
    3. Greedily select top-k files by Î”Q impact
    4. Generate actionable tasks with specific recommendations

Formula:
    Î”Q(file) = Î£(w_i Ã— penalty_i)
    where:
        w_complexity = 5.0 (high impact on maintainability)
        w_todos = 2.0 (technical debt indicators)
        w_issues = 3.0 (quality issues)
        w_hotspot = 4.0 (change frequency risk)
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import List


@dataclass
class RefactoringTask:
    """A single refactoring task with priority and recommendations."""

    id: int
    file_path: str
    priority: str  # "critical", "high", "medium", "low"
    delta_q: float  # Expected quality improvement
    current_metrics: dict
    issues: List[str]
    recommendations: List[str]
    estimated_effort: str  # "15 min", "1 hour", "2-4 hours"

    def to_dict(self) -> dict:
        """Convert task to dictionary for JSON export."""
        return {
            "id": self.id,
            "file_path": self.file_path,
            "priority": self.priority,
            "delta_q": round(self.delta_q, 2),
            "current_metrics": self.current_metrics,
            "issues": self.issues,
            "recommendations": self.recommendations,
            "estimated_effort": self.estimated_effort,
        }

    def to_markdown(self) -> str:
        """Format task as Markdown."""
        priority_emoji = {
            "critical": "ğŸ”´",
            "high": "ğŸŸ ",
            "medium": "ğŸŸ¡",
            "low": "ğŸŸ¢",
        }

        lines = [
            f"### Task #{self.id}: {self.file_path}",
            f"**Priority**: {priority_emoji.get(self.priority, 'âšª')} {self.priority.upper()}",
            f"**Expected Î”Q**: +{self.delta_q:.1f} points",
            f"**Estimated effort**: {self.estimated_effort}",
            "",
            "**Current metrics**:",
        ]

        for key, value in self.current_metrics.items():
            lines.append(f"- {key}: {value}")

        lines.extend(["", "**Issues**:"])
        for issue in self.issues:
            lines.append(f"- {issue}")

        lines.extend(["", "**Recommendations**:"])
        for i, rec in enumerate(self.recommendations, 1):
            lines.append(f"{i}. {rec}")

        lines.append("")
        return "\n".join(lines)

    def to_github_issue(self, repo_name: str = "repoq") -> dict:
        """Format task as GitHub Issue payload."""
        labels = [self.priority, "refactoring", "tech-debt"]

        body_lines = [
            f"## ğŸ“‹ Refactoring Task: `{self.file_path}`",
            "",
            f"**Expected quality improvement**: Î”Q = +{self.delta_q:.1f}",
            f"**Estimated effort**: {self.estimated_effort}",
            "",
            "### Current Metrics",
            "",
        ]

        for key, value in self.current_metrics.items():
            body_lines.append(f"- **{key}**: {value}")

        body_lines.extend(["", "### Issues Detected", ""])
        for issue in self.issues:
            body_lines.append(f"- [ ] {issue}")

        body_lines.extend(["", "### Recommended Actions", ""])
        for i, rec in enumerate(self.recommendations, 1):
            body_lines.append(f"{i}. {rec}")

        body_lines.extend(
            [
                "",
                "---",
                "*Generated by RepoQ refactor-plan command*",
            ]
        )

        return {
            "title": f"Refactor: {Path(self.file_path).name} (Î”Q: +{self.delta_q:.1f})",
            "body": "\n".join(body_lines),
            "labels": labels,
        }


@dataclass
class RefactoringPlan:
    """Complete refactoring plan with multiple tasks."""

    tasks: List[RefactoringTask]
    total_delta_q: float
    baseline_q: float
    projected_q: float

    def to_markdown(self) -> str:
        """Format plan as Markdown report."""
        lines = [
            "# ğŸ”§ Refactoring Plan",
            "",
            "## Executive Summary",
            "",
            f"- **Current Q-score**: {self.baseline_q:.2f}",
            f"- **Projected Q-score**: {self.projected_q:.2f}",
            f"- **Total Î”Q**: +{self.total_delta_q:.1f}",
            f"- **Tasks**: {len(self.tasks)}",
            "",
            "## Priority Breakdown",
            "",
        ]

        # Count by priority
        priority_counts = {}
        for task in self.tasks:
            priority_counts[task.priority] = priority_counts.get(task.priority, 0) + 1

        for priority in ["critical", "high", "medium", "low"]:
            count = priority_counts.get(priority, 0)
            if count > 0:
                lines.append(f"- **{priority.capitalize()}**: {count} tasks")

        lines.extend(["", "## Tasks", ""])

        for task in self.tasks:
            lines.append(task.to_markdown())

        lines.extend(
            [
                "---",
                "",
                "## Execution Strategy",
                "",
                "1. **Critical tasks**: Fix immediately (blocking issues)",
                "2. **High priority**: Include in current sprint",
                "3. **Medium priority**: Plan for next sprint",
                "4. **Low priority**: Backlog for future iterations",
                "",
                "**Success criteria**:",
                f"- âœ… Q-score â‰¥ {self.projected_q:.2f}",
                "- âœ… All critical tasks resolved",
                "- âœ… No regression in test coverage",
                "- âœ… PCQ â‰¥ 0.8 (gaming resistance)",
            ]
        )

        return "\n".join(lines)


def calculate_delta_q(file_data: dict) -> float:
    """Calculate expected Î”Q if file issues are fixed.

    Args:
        file_data: File metrics dictionary from JSON-LD

    Returns:
        Expected quality score improvement (Î”Q)

    Weights based on Phase 4 Q-formula:
        - Complexity: 5.0 (high maintainability impact)
        - TODOs: 2.0 (tech debt indicators)
        - Issues: 3.0 (quality problems)
        - Hotspot score: 4.0 (change frequency risk)
    """
    complexity = file_data.get("complexity", 0) or 0
    todos = len(file_data.get("todos", [])) if isinstance(file_data.get("todos"), list) else 0
    issues = len(file_data.get("issues", [])) if isinstance(file_data.get("issues"), list) else 0
    hotspot_score = file_data.get("hotspotScore", 0) or 0

    # Weights from Q-formula
    w_complexity = 5.0
    w_todos = 2.0
    w_issues = 3.0
    w_hotspot = 4.0

    # Calculate penalties (higher = worse)
    complexity_penalty = max(0, complexity - 5)  # Penalty if complexity > 5
    todo_penalty = todos
    issue_penalty = issues
    hotspot_penalty = max(0, hotspot_score - 50)  # Penalty if hotspot > 50

    delta_q = (
        w_complexity * complexity_penalty
        + w_todos * todo_penalty
        + w_issues * issue_penalty
        + w_hotspot * (hotspot_penalty / 10.0)  # Scale down hotspot
    )

    return delta_q


def _estimate_function_delta_q(func: dict, file_loc: int) -> float:
    """Estimate Î”Q improvement from refactoring a single function (T1.3).

    Args:
        func: Function metrics dict with cyclomaticComplexity, linesOfCode, etc.
        file_loc: Total file LOC for file impact factor

    Returns:
        Expected Î”Q improvement (0.0 if function doesn't need refactoring)

    Formula:
        Î”Q = (CCN_delta Ã— w_ccn + LOC_delta Ã— w_loc) Ã— file_factor
        where:
            CCN_delta = max(0, current_CCN - target_CCN)
            LOC_delta = max(0, current_LOC - target_LOC)
            file_factor = 1.0 + (file_LOC / 1000.0)  # Larger files benefit more
    """
    current_ccn = func.get("cyclomaticComplexity", 0)
    current_loc = func.get("linesOfCode", 0)

    # Target thresholds
    target_ccn = 10.0
    target_loc = current_loc * 0.7  # Aim for 30% reduction

    # Calculate deltas (only positive improvements)
    ccn_delta = max(0, current_ccn - target_ccn)
    loc_delta = max(0, current_loc - target_loc)

    # Weights
    w_ccn = 5.0  # High weight for complexity reduction
    w_loc = 0.5  # Lower weight for LOC reduction

    # File impact factor (larger files benefit more from extraction)
    file_factor = 1.0 + (file_loc / 1000.0)

    # Calculate Î”Q
    delta_q = (ccn_delta * w_ccn + loc_delta * w_loc) * file_factor

    return round(delta_q, 1)


def _get_function_priority(delta_q: float) -> str:
    """Determine refactoring priority based on Î”Q (T1.3).

    Args:
        delta_q: Expected Î”Q improvement

    Returns:
        Priority level: "critical", "high", "medium", or "low"
    """
    if delta_q >= 80:
        return "critical"
    elif delta_q >= 40:
        return "high"
    elif delta_q >= 20:
        return "medium"
    else:
        return "low"


def _generate_function_recommendations(
    functions: List[dict], loc: int, complexity: float
) -> List[str]:
    """Generate per-function refactoring recommendations with Î”Q estimation.

    Args:
        functions: List of function metrics dicts
        loc: Total file LOC for impact calculation
        complexity: File-level complexity for fallback validation

    Returns:
        List of formatted recommendations for complex functions
    """
    recommendations = []
    complex_funcs = [f for f in functions if f.get("cyclomaticComplexity", 0) >= 10]

    if not complex_funcs:
        # If file complexity high but no individual function >10
        if complexity >= 10:
            recommendations.append(
                f"âš ï¸ File complexity={complexity} but no function >10 "
                "(verify metrics or refactor distributed complexity)"
            )
        return recommendations

    # Calculate Î”Q for each function
    file_delta_q_total = 0.0
    for func in complex_funcs:
        delta_q = _estimate_function_delta_q(func, loc)
        func["_delta_q"] = delta_q
        file_delta_q_total += delta_q

    # Sort by Î”Q descending (highest impact first)
    complex_funcs.sort(key=lambda f: f.get("_delta_q", 0), reverse=True)

    # Generate recommendations for top 3 highest impact functions
    for func in complex_funcs[:3]:
        fname = func.get("name", "unknown")
        fccn = func.get("cyclomaticComplexity", 0)
        flines = f"{func.get('startLine', '?')}-{func.get('endLine', '?')}"
        floc = func.get("linesOfCode", 0)
        delta_q = func.get("_delta_q", 0.0)

        # Calculate percentage of file's total potential
        pct = int((delta_q / file_delta_q_total * 100)) if file_delta_q_total > 0 else 0

        # Priority indicator
        priority = _get_function_priority(delta_q)
        priority_emoji = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
            priority, "âšª"
        )

        # Estimate effort
        if fccn >= 20:
            effort_str = "3-4 hours"
        elif fccn >= 15:
            effort_str = "2-3 hours"
        elif fccn >= 10:
            effort_str = "1-2 hours"
        else:
            effort_str = "30-60 min"

        recommendations.append(
            f"{priority_emoji} Refactor function `{fname}` "
            f"(CCN={fccn}, LOC={floc}, lines {flines})\n"
            f"   â†’ Expected Î”Q: +{delta_q:.1f} points ({pct}% of file's potential)\n"
            f"   â†’ Estimated effort: {effort_str}"
        )

    return recommendations


def _generate_file_level_recommendations(
    complexity: float, loc: int, todos: int, functions: List[dict]
) -> List[str]:
    """Generate file-level refactoring recommendations (fallback when no functions).

    Args:
        complexity: File-level cyclomatic complexity
        loc: Lines of code
        todos: Number of TODO comments
        functions: List of function metrics (used to check if fallback needed)

    Returns:
        List of file-level recommendations
    """
    recommendations = []

    # Complexity recommendations (only if no per-function analysis)
    if not functions:
        if complexity >= 10:
            recommendations.append(
                f"ğŸ”´ **Critical**: Reduce cyclomatic complexity from {complexity} to <10 "
                "(split into smaller functions)"
            )
        elif complexity >= 6:
            recommendations.append(
                f"ğŸŸ¡ Extract complex logic into helper functions (current: {complexity})"
            )

    # LOC recommendations
    if loc > 500:
        recommendations.append(
            f"ğŸ“ Consider splitting file ({loc} LOC) into smaller modules (<300 LOC)"
        )

    # TODO recommendations
    if todos >= 5:
        recommendations.append(f"ğŸ“ Resolve {todos} TODO comments (prioritize blocking issues)")
    elif todos > 0:
        recommendations.append(f"ğŸ“ Address {todos} TODO comment(s)")

    return recommendations


def _generate_issue_recommendations(issues: List) -> List[str]:
    """Generate issue-specific refactoring recommendations.

    Args:
        issues: List of issue identifiers or dicts

    Returns:
        List of issue-specific recommendations
    """
    recommendations = []

    for issue in issues:
        if isinstance(issue, str):
            # Parse issue ID to get type
            if "hotspot" in issue:
                recommendations.append("ğŸ”¥ Reduce change frequency (refactor to stabilize)")
            elif "complexity" in issue:
                recommendations.append("ğŸ”§ Simplify control flow (reduce nested logic)")

    return recommendations


def generate_recommendations(file_data: dict) -> List[str]:
    """Generate specific refactoring recommendations based on metrics.

    Args:
        file_data: File metrics dictionary

    Returns:
        List of actionable recommendations (limited to top 5)
    """
    # Extract metrics
    complexity = file_data.get("complexity", 0) or 0
    loc = file_data.get("linesOfCode", 0) or 0
    todos = len(file_data.get("todos", [])) if isinstance(file_data.get("todos"), list) else 0
    issues = file_data.get("issues", [])
    functions = file_data.get("functions", [])

    # Generate recommendations from different analyzers
    recommendations = []

    # 1. Per-function analysis (highest priority)
    if functions:
        recommendations.extend(_generate_function_recommendations(functions, loc, complexity))

    # 2. File-level metrics (LOC, TODOs, complexity fallback)
    recommendations.extend(_generate_file_level_recommendations(complexity, loc, todos, functions))

    # 3. Issue-specific recommendations
    recommendations.extend(_generate_issue_recommendations(issues))

    # 4. Default if no recommendations generated
    if not recommendations:
        recommendations.append("âœ… Maintain current quality (minor cleanup possible)")

    return recommendations[:5]  # Limit to top 5


def estimate_effort(delta_q: float, complexity: float, loc: int) -> str:
    """Estimate refactoring effort based on impact and size.

    Args:
        delta_q: Expected quality improvement
        complexity: Cyclomatic complexity
        loc: Lines of code

    Returns:
        Human-readable effort estimation
    """
    # High impact + high complexity = more effort
    effort_score = delta_q + (complexity * 0.5) + (loc / 100.0)

    if effort_score >= 40:
        return "4-8 hours (complex refactoring)"
    elif effort_score >= 20:
        return "2-4 hours (moderate refactoring)"
    elif effort_score >= 10:
        return "1-2 hours (focused refactoring)"
    else:
        return "15-30 minutes (quick fixes)"


def assign_priority(delta_q: float, complexity: float) -> str:
    """Assign priority based on Î”Q and complexity.

    Args:
        delta_q: Expected quality improvement
        complexity: Cyclomatic complexity

    Returns:
        Priority level: "critical", "high", "medium", or "low"
    """
    if delta_q >= 30 or complexity >= 10:
        return "critical"
    elif delta_q >= 15 or complexity >= 7:
        return "high"
    elif delta_q >= 5:
        return "medium"
    else:
        return "low"


def _load_and_filter_files(
    jsonld_path: Path,
    min_delta_q: float,
) -> tuple[list[dict], list[dict]]:
    """Load JSON-LD data and filter files by minimum Î”Q.

    Args:
        jsonld_path: Path to JSON-LD quality analysis file
        min_delta_q: Minimum Î”Q threshold for inclusion

    Returns:
        Tuple of (filtered file scores, all files for baseline calculation)
    """
    if not jsonld_path.exists():
        raise FileNotFoundError(f"JSON-LD file not found: {jsonld_path}")

    data = json.loads(jsonld_path.read_text(encoding="utf-8"))

    # Extract files
    files = data.get("files", [])
    if not isinstance(files, list):
        files = list(files.values()) if isinstance(files, dict) else []

    # Calculate Î”Q for each file and filter
    file_scores = []
    for file_data in files:
        delta_q = calculate_delta_q(file_data)

        if delta_q >= min_delta_q:
            file_scores.append(
                {
                    "path": file_data.get("path", file_data.get("fileName", "unknown")),
                    "delta_q": delta_q,
                    "data": file_data,
                }
            )

    return file_scores, files


def _build_refactoring_task(
    task_id: int,
    item: dict,
) -> RefactoringTask:
    """Build a single refactoring task from file score data.

    Args:
        task_id: Sequential task ID
        item: Dict containing path, delta_q, and file data

    Returns:
        Complete RefactoringTask with metrics and recommendations
    """
    file_data = item["data"]
    delta_q = item["delta_q"]
    path = item["path"]

    complexity = file_data.get("complexity", 0) or 0
    loc = file_data.get("linesOfCode", 0) or 0
    todos = len(file_data.get("todos", [])) if isinstance(file_data.get("todos"), list) else 0
    issues = file_data.get("issues", [])

    current_metrics = {
        "Complexity": complexity,
        "LOC": loc,
        "TODOs": todos,
        "Issues": len(issues) if isinstance(issues, list) else 0,
    }

    # Generate issues list
    issue_descriptions = []
    if complexity >= 6:
        issue_descriptions.append(f"High cyclomatic complexity ({complexity})")
    if todos > 0:
        issue_descriptions.append(f"{todos} unresolved TODO(s)")
    if loc > 500:
        issue_descriptions.append(f"Large file size ({loc} LOC)")

    recommendations = generate_recommendations(file_data)
    effort = estimate_effort(delta_q, complexity, loc)
    priority = assign_priority(delta_q, complexity)

    return RefactoringTask(
        id=task_id,
        file_path=path,
        priority=priority,
        delta_q=delta_q,
        current_metrics=current_metrics,
        issues=issue_descriptions or ["No critical issues"],
        recommendations=recommendations,
        estimated_effort=effort,
    )


def _calculate_plan_metrics(
    file_scores: list[dict],
    all_files: list[dict],
    total_delta_q: float,
) -> tuple[float, float]:
    """Calculate baseline and projected quality scores.

    Args:
        file_scores: Filtered file scores above threshold
        all_files: All files for baseline estimation
        total_delta_q: Sum of Î”Q from selected tasks

    Returns:
        Tuple of (baseline_q, projected_q)
    """
    # Try to extract baseline from data if available
    baseline_q = 0.0
    if not all_files:
        baseline_q = 50.0  # Default neutral score

    if baseline_q == 0.0:
        # Estimate baseline from penalties
        total_penalty = sum(item["delta_q"] for item in file_scores)
        baseline_q = max(0, 100.0 - (total_penalty / len(all_files) * 10 if all_files else 0))

    projected_q = min(100.0, baseline_q + total_delta_q)
    return baseline_q, projected_q


def generate_refactoring_plan(
    jsonld_path: str | Path,
    top_k: int = 10,
    min_delta_q: float = 3.0,
) -> RefactoringPlan:
    """Generate refactoring plan from analysis results.

    Args:
        jsonld_path: Path to JSON-LD quality analysis file
        top_k: Maximum number of tasks to generate (greedy selection)
        min_delta_q: Minimum Î”Q threshold for inclusion

    Returns:
        Complete refactoring plan with prioritized tasks

    Algorithm:
        1. Load quality data from JSON-LD
        2. Calculate Î”Q for each file
        3. Filter by min_delta_q threshold
        4. Sort by Î”Q descending (greedy)
        5. Select top-k files
        6. Generate recommendations and estimate effort
        7. Assign priorities
    """
    jsonld_path = Path(jsonld_path)

    # Load and filter files by Î”Q threshold
    file_scores, all_files = _load_and_filter_files(jsonld_path, min_delta_q)

    # Sort by Î”Q descending (greedy selection) and select top-k
    file_scores.sort(key=lambda x: x["delta_q"], reverse=True)
    selected = file_scores[:top_k]

    # Generate tasks from selected files
    tasks = []
    total_delta_q = 0.0

    for i, item in enumerate(selected, 1):
        task = _build_refactoring_task(i, item)
        tasks.append(task)
        total_delta_q += item["delta_q"]

    # Calculate quality metrics
    baseline_q, projected_q = _calculate_plan_metrics(file_scores, all_files, total_delta_q)

    return RefactoringPlan(
        tasks=tasks,
        total_delta_q=total_delta_q,
        baseline_q=baseline_q,
        projected_q=projected_q,
    )
